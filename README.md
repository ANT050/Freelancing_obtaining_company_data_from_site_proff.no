# Проект для сбора данных о компаниях с Proff.no

![GitHub](https://img.shields.io/github/license/ANT050/Freelancing_obtaining_company_data_from_site_proff.no?color=green&label=MIT%20License)

## Описание

Этот проект представляет собой скрипт на Python для сбора данных о компаниях с веб-сайта Proff.no
и сохранения этой информации в формате Excel.
Скрипт выполняет запросы к веб-сайту, извлекает данные о компаниях, включая название, телефоны, адрес,
электронную почту и веб-сайт компании, а затем сохраняет эти данные в Excel-файл.

## Использование

1. Установите необходимые библиотеки, если они еще не установлены.
   Вы можете использовать команду `pip install -r requirements.txt` для установки библиотек, указанных в
   файле `requirements.txt`.

2. Запустите скрипт, выполнив команду:

   > python archdaily_website.py

   Скрипт начнет собирать данные о компаниях с веб-сайта Proff.no.
   По умолчанию, скрипт будет обрабатывать все страницы результатов.

3. По завершении выполнения скрипта, данные будут сохранены в файл `companies_data.xlsx`.

## Параметры конфигурации

Вы можете настроить параметры скрипта, изменив значения в функции `main()` в файле `archdaily_website.py`:

- `base_url`: Начальная страница для сбора данных.
- `headers`: Заголовки HTTP-запросов, включая User-Agent, Accept, и другие.

## Зависимости

Для работы скрипта необходимы следующие библиотеки:

- `aiohttp` для выполнения асинхронных HTTP-запросов.
- `BeautifulSoup` для парсинга HTML-страниц.
- `pandas` для работы с данными в формате Excel.
- `lxml` для более эффективного парсинга HTML-страниц с использованием BeautifulSoup.
- `openpyxl` для работы с данными в формате Excel.

Убедитесь, что вы установили эти библиотеки перед запуском скрипта.

## Примечания

- Этот скрипт предназначен только для образовательных целей

---

